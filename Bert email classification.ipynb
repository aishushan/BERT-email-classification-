{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5CFBuyEbZyz"
      },
      "source": [
        "<h2 align=\"center\">BERT_Email_Classification</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, we will build a spam detection model. The spam detection model will classify emails as spam or not spam. This will be used to filter unwanted and unsolicited emails. We will build this model using BERT and Tensorflow.\n",
        "\n",
        "BERT will be used to generate sentence encoding for all emails. Finally, we will use Tensorflow to build the neural networks. Tensorflow will create the input and output layers of our machine learning model."
      ],
      "metadata": {
        "id": "Lvuwji11oeVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "OQ7SDzShrDVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing important packages"
      ],
      "metadata": {
        "id": "PBw3YgISrOOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensorflow_text: It will allow us to work with text. In this tutorial, we are solving a text-classification problem"
      ],
      "metadata": {
        "id": "FxbdNalNq5Sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-text==2.6.0\n"
      ],
      "metadata": {
        "id": "j1Y_C7hShgbY",
        "outputId": "012ea366-1971-48a1-9d21-6775a4ffb30e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-text==2.6.0 in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: tensorflow<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.6.0) (2.6.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.6.0) (0.12.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.43.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.37.1)\n",
            "Requirement already satisfied: keras<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (2.6.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (2.6.0)\n",
            "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (2.6.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.12)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions<3.11,>=3.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.10.0.2)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (5.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.3.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text==2.6.0) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensorflow: It is the machine learning package used to build the neural network. It will create the input and output layers of our machine learning model.\n",
        "\n",
        "tensorflow_hub: It contains a pre-trained machine model used to build our text classification. Our pre-trained model is BERT. We will re-use the BERT model and fine-tune it to meet our needs.\n",
        "\n",
        "tensorflow_text: It will allow us to work with text. In this tutorial, we are solving a text-classification problem.\n",
        "\n",
        "pandas: We will use Pandas to load our dataset. We also use Pandas for data manipulation and analysis. It gives us a clear overview of how our dataset is structured."
      ],
      "metadata": {
        "id": "LWQzFioArk63"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12VGb57gbZzA"
      },
      "outputs": [],
      "source": [
        "#import above mentioned libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl_7qiq-bZzD"
      },
      "source": [
        "Import the dataset from here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV7kUz6gbZzE",
        "outputId": "b60d8b4b-4904-4fa2-d79c-21b8cb88e3e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c277eac5-ca8f-4f7b-a8fe-dbf765fb5ffd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c277eac5-ca8f-4f7b-a8fe-dbf765fb5ffd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c277eac5-ca8f-4f7b-a8fe-dbf765fb5ffd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c277eac5-ca8f-4f7b-a8fe-dbf765fb5ffd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Category                                            Message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#read the data set\n",
        "df =pd.read_csv('spam.csv')\n",
        "#print top 5 data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "our dataset has two categories: ham and spam. ham represents the emails that are not spam, this are emails from a trusted source. spam represents emails from an unknown source.\n",
        "\n",
        "The dataset also has the Message column. This column represents the email messages. Let’s see the individual value count for the spam and ham emails."
      ],
      "metadata": {
        "id": "UOGLn2sFsVNH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4aZRX7dbZzI",
        "outputId": "24449fd0-fecc-4b3e-a453-59bae79f66e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: Category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "#checking the count of category\n",
        "df['Category'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have 4825 ham emails and 747 spam emails. The ham email has a significantly higher number.\n",
        "\n",
        "The ratio of the two categories is shown below:"
      ],
      "metadata": {
        "id": "OXLEsyoaukH_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzd3v8SBbZzK",
        "outputId": "5e702547-9da7-4956-d787-0ce546bf9f27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15481865284974095"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#divide ham with spam to check the ratio\n",
        "747/4825"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This result implies that about 15% are spam emails and 85% of ham emails. This indicates a class imbalance. We need to balance the two classes to reduce bias during model training."
      ],
      "metadata": {
        "id": "13QTAqukyNCD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw_wDVmkbZzL"
      },
      "source": [
        "**15% spam emails, 85% ham emails: This indicates class imbalance**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Balancing dataset\n",
        "We have various techniques that are used to balance the dataset. In this tutorial, we will use the most simple approach. We will reduce 4825 of the majority class to 747. This will make the two classes balanced.\n",
        "\n",
        "we balance the two classes, let’s create data frames for the individual classes."
      ],
      "metadata": {
        "id": "qdXVBG5lyeoC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgFI1jg3bZzN",
        "outputId": "801a193e-44fa-43c6-ca40-c3a867824368",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(747, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#checking the shape of spam\n",
        "df_spam = df[df['Category']=='spam']\n",
        "\n",
        "#print shape\n",
        "df_spam.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z-7-kbxbZzP",
        "outputId": "36fcc3c6-ceba-400b-ff4b-85c8849e2e2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4825, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "#checking the shape of ham\n",
        "df_ham = df[df['Category']=='ham']\n",
        "#print shape\n",
        "df_ham.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have created the two data frames, we will reduce the number of the ham class to be equal to the spam class.\n"
      ],
      "metadata": {
        "id": "zPxPq9zu0KnK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M13oNuQ4bZzQ",
        "outputId": "1f0b45b3-1c4d-4e1a-b39d-54b4e2bea446",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(747, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "#take shape [0]\n",
        "df_ham_downsampled = df_ham.sample(df_spam.shape[0])\n",
        "\n",
        "#print the shape\n",
        "df_ham_downsampled.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will save the new class into a df_ham_downsampled variable. We need to concatenate the two balanced classes into a single data frame."
      ],
      "metadata": {
        "id": "__buvWm73ZH7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bF6rbrfbZzR",
        "outputId": "766aabc9-84c2-4f24-a31d-6af44cb2136e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1494, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "#concat the df_ham_downsampled, df_spam\n",
        "df_balanced = pd.concat([df_ham_downsampled, df_spam])\n",
        "#print the shape\n",
        "df_balanced.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pd.concat method will concatenate df_ham_downsampled and df_spam into a single data frame. It will save the dataset into a variable df_balanced."
      ],
      "metadata": {
        "id": "n7T9m7nx39Fe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qj_KpqPrbZzS",
        "outputId": "5ed57a17-0176-4672-ba25-6383274623a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     747\n",
              "spam    747\n",
              "Name: Category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "#checking the balanced count of category\n",
        "df_balanced['Category'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adding labels\n",
        "We need to label our dataset into 1 and 0. 1 will represent the data samples that belong to the spam class. 0 will represent the data samples that belong to the ham class.<br>\n",
        "We use lambda to write our logic. The apply method will run the written logic. This will enable us to label our dataset."
      ],
      "metadata": {
        "id": "E0nJ6oLa4EtH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "PO2yULZCbZzU",
        "outputId": "085d1a6e-c17f-49cb-b22c-6b684ead7a25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-46fdc6ae-dfca-488b-9959-cde401b3bc45\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1069</th>\n",
              "      <td>spam</td>\n",
              "      <td>Someone U know has asked our dating service 2 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2932</th>\n",
              "      <td>ham</td>\n",
              "      <td>Hi' Test on  &amp;lt;#&amp;gt; rd ....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4377</th>\n",
              "      <td>spam</td>\n",
              "      <td>If you don't, your prize will go to another cu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5018</th>\n",
              "      <td>spam</td>\n",
              "      <td>Dear 0776xxxxxxx U've been invited to XCHAT. T...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3913</th>\n",
              "      <td>spam</td>\n",
              "      <td>You have an important customer service announc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46fdc6ae-dfca-488b-9959-cde401b3bc45')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46fdc6ae-dfca-488b-9959-cde401b3bc45 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46fdc6ae-dfca-488b-9959-cde401b3bc45');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Category                                            Message  spam\n",
              "1069     spam  Someone U know has asked our dating service 2 ...     1\n",
              "2932      ham                     Hi' Test on  &lt;#&gt; rd ....     0\n",
              "4377     spam  If you don't, your prize will go to another cu...     1\n",
              "5018     spam  Dear 0776xxxxxxx U've been invited to XCHAT. T...     1\n",
              "3913     spam  You have an important customer service announc...     1"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#apply the condition with lambda\n",
        "#if spam print l\n",
        "#else print 0\n",
        "df_balanced['spam']=df_balanced['Category'].apply(lambda x: 1 if x=='spam' else 0)\n",
        "\n",
        "#print the top partial view\n",
        "df_balanced.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see that the dataset is labeled into two. Some of the data samples are labeled 1 while others are labeled 0. We now need to split our labeled dataset."
      ],
      "metadata": {
        "id": "k0JZpGK74oPv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKbrtnbRbZzV"
      },
      "source": [
        "#Split it into training and test dataset\n",
        "\n",
        "We split our dataset into two sets, the first set will be used for training and the second set will be used for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnTw4-MmbZzW"
      },
      "outputs": [],
      "source": [
        "#import train_test_split from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "#use train_test_split in df_balanced['Message'],df_balanced['spam'], stratify=df_balanced['spam']\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_balanced['Message'],df_balanced['spam'], stratify=df_balanced['spam'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "wCAoAUsabZzY",
        "outputId": "e7126076-bb99-4f9e-ed35-70f11008dac7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3509    Camera quite good, 10.1mega pixels, 3optical a...\n",
              "4592    Well done ENGLAND! Get the official poly ringt...\n",
              "4991    Phony £350 award - Todays Voda numbers ending ...\n",
              "5476    Yes princess! I want to please you every night...\n",
              "Name: Message, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "#print the head of X_train\n",
        "x_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use stratify to ensure equal distribution of classes in the train and test sample. This ensures we have an equal amount of spam and ham emails after splitting. After splitting the dataset, we can start working with BERT."
      ],
      "metadata": {
        "id": "8C1OTIC_5Qck"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVzS6I4xbZzb"
      },
      "source": [
        "#Getting started with BERT\n",
        "BERT stands for Bidirectional Encoder Representations from Transformers. BERT models help machines understand and interpret the meaning of the text. It uses immediately preceding text to understand the context. It also checks the relationships of words within a sentence to give the actual meaning of words.\n",
        "\n",
        "BERT will then convert a given sentence into an embedding vector. Embedding vector is used to represent the unique words in a given document. BERT ensures words with the same meaning will have a similar representation.\n",
        "\n",
        "Machine learning does not work with text but works well with numbers. That’s why BERT converts the input text into embedding vectors. The embedding vectors are numbers with which the model can easily work.\n",
        "\n",
        "The BERT process undergoes two stages: Preprocessing and encoding.\n",
        "\n",
        "\n",
        "Preprocessing\n",
        "Preprocessing is the first stage in BERT. This stage involves removing noise from our dataset. In this stage, BERT will clean the dataset. It also removes duplicate records from the dataset.\n",
        "\n",
        "It will also format the dataset so that it can be easy to use during model training. This will increase the model performance.\n",
        "\n",
        "Encoding\n",
        "Because machine learning does not work well with the text, we need to convert the text into real numbers. This process is known as encoding. BERT will convert a given sentence into an embedding vector."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the BERT model\n",
        "BERT models are usually pre-trained. They are available in TensorFlow Hub. TensorFlow Hub contains all the pre-trained machine learning models that are downloaded.\n",
        "\n",
        "We will download two models, one to perform preprocessing and the other one for encoding. The links for the models are shown below.\n",
        "\n",
        "for bert_preprocess:<br>\n",
        "https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n",
        "\n",
        "for bert_encoder:<br>\n",
        "\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n"
      ],
      "metadata": {
        "id": "oJCT24gQ5kNQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spe5N6zGbZzb"
      },
      "outputs": [],
      "source": [
        "#download the pretrained models with hub.kerasLayer\n",
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After downloading the model, let’s start building our model using TensorFlow."
      ],
      "metadata": {
        "id": "__hW3Ih75nsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building model using TensorFlow\n",
        "There are two types of models that you can build in TensorFlow. Sequential model and a functional model. In a sequential model, layers are built on top of each other, layer by layer. In a sequential model, we don’t have multiple inputs and outputs.\n",
        "\n",
        "Functional models are more robust and flexible. They do not create layers in sequential order. In the functional model, we have multiple inputs and outputs. This tutorial will use the functional approach to build our model. We will start by initializing the BERT layers."
      ],
      "metadata": {
        "id": "ArXBq6g35rCA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lM2aHqAbZzj"
      },
      "source": [
        "<h4>Build Model</h4>\n",
        "\n",
        "we are creating an input layer using tf.keras.layers.Input method. We will use the preprocessed_text as input for this layer.\n",
        "\n",
        "The bert_encoder function will then convert the preprocessed text into embedding vectors. This will be the output of this layer. The outputs will then be fed into the neural network layers.\n",
        "\n",
        "The neural network has two layers, the Dropout layer, and the Dense layer.\n",
        "\n",
        "Dropout’ layer<br>\n",
        "This layer will be used to prevent model overfitting. We will use 0.1% of the neurons to handle overfitting. Overfitting happens when a model perfectly learns from training data but performs poorly in testing. We also give it the name dropout.\n",
        "\n",
        "Since we are using the functional approach to build the model, we add the input for this layer as a function using (outputs['pooled_output']). This input was the output of the BERT layers.\n",
        "\n",
        "‘Dense’ layer<br>\n",
        "It only has one neuron. We also initialize the activation function as sigmoid. sigmoid is used when we have output values that between 0 and 1. In our case, when making predictions, the prediction probability will lie between 0 and 1. That’s why it is best suited.\n",
        "\n",
        "The model will use the text_input as inputs and will have only one single output. We will display the model summary so that we can see all the input and output layers used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FpwKjFObZzk"
      },
      "outputs": [],
      "source": [
        "# Bert layers\n",
        "#keras.layers.Input with shape=(),dtype=tf.string,name='text\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "\n",
        "#preprocessed_text\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "#pass the preprocessed_text with bert_encoder\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "# Neural network layers\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "# Use inputs and outputs to construct a final model\n",
        "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will print the model summary."
      ],
      "metadata": {
        "id": "6RZEQeD4CnXB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EgeOrb8bZzo",
        "outputId": "3e063d71-881a-4b8a-a9a8-a53bbbf6fabf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_2 (KerasLayer)      {'input_mask': (None 0           text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_3 (KerasLayer)      {'sequence_output':  109482241   keras_layer_2[0][0]              \n",
            "                                                                 keras_layer_2[0][1]              \n",
            "                                                                 keras_layer_2[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 768)          0           keras_layer_3[0][13]             \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            769         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 769\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#print the summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The all the input and output layers we have initialized for our model. The output also shows the total params, trainable params, and non-trainable params.\n",
        "\n",
        "Total params: It represents all the parameters in our model.\n",
        "\n",
        "Trainable params: It represents the parameters that we will train.\n",
        "\n",
        "Non-trainable params: These parameters are from the BERT model. They are already trained."
      ],
      "metadata": {
        "id": "TEnE5r1-1sP3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFpmjWpDbZzq",
        "outputId": "8bf6a746-f80e-410d-f9bc-d6a90b732d8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1120"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "#print the len\n",
        "len(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Optimizer is used to improve the model performance and reduce errors that occur during model training. We use the adam optimizer.\n",
        "\n",
        "Metrics will be used to check the model performance so that we can know how we trained our model. We set the BinaryAccuracy(name='accuracy') which will be used to calculate the accuracy score of the model.\n",
        "\n",
        "The Loss function is used to calculate the model error during the training phase. We use binary_crossentropy as our loss function because our output is binary. The output can either be a 0 or 1."
      ],
      "metadata": {
        "id": "UJNedv-H1ynC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omqD2jJqbZzq"
      },
      "outputs": [],
      "source": [
        "#METRICS\n",
        "#accuaracy\n",
        "#precision\n",
        "#recall\n",
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "#compiling our model\n",
        "#optimizer = adam\n",
        "#loss=binary_crossentropy\n",
        "#metrics =metrics\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = METRICS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt60X_TgbZzr"
      },
      "source": [
        "<h4>Train the model</h4>\n",
        "\n",
        "The model learns from the training data samples. The model will identify\n",
        "patterns in the training dataset and gain knowledge.\n",
        "\n",
        "We will specify the number of epochs as 10. The model will iterate through the dataset ten times and print the accuracy score after each iteration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N9a3I9GbZzs",
        "outputId": "e93c0123-14f3-4cf1-d482-319b42d56e87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "35/35 [==============================] - 35s 652ms/step - loss: 0.6636 - accuracy: 0.6098 - precision: 0.6128 - recall: 0.5964\n",
            "Epoch 2/10\n",
            "35/35 [==============================] - 20s 579ms/step - loss: 0.5337 - accuracy: 0.7848 - precision: 0.7813 - recall: 0.7911\n",
            "Epoch 3/10\n",
            "35/35 [==============================] - 20s 582ms/step - loss: 0.4530 - accuracy: 0.8438 - precision: 0.8360 - recall: 0.8554\n",
            "Epoch 4/10\n",
            "35/35 [==============================] - 20s 582ms/step - loss: 0.4048 - accuracy: 0.8571 - precision: 0.8484 - recall: 0.8696\n",
            "Epoch 5/10\n",
            "35/35 [==============================] - 20s 582ms/step - loss: 0.3733 - accuracy: 0.8723 - precision: 0.8730 - recall: 0.8714\n",
            "Epoch 6/10\n",
            "35/35 [==============================] - 20s 585ms/step - loss: 0.3418 - accuracy: 0.8768 - precision: 0.8564 - recall: 0.9054\n",
            "Epoch 7/10\n",
            "35/35 [==============================] - 20s 583ms/step - loss: 0.3254 - accuracy: 0.8821 - precision: 0.8905 - recall: 0.8714\n",
            "Epoch 8/10\n",
            "35/35 [==============================] - 20s 582ms/step - loss: 0.3139 - accuracy: 0.8884 - precision: 0.8822 - recall: 0.8964\n",
            "Epoch 9/10\n",
            "35/35 [==============================] - 20s 582ms/step - loss: 0.2945 - accuracy: 0.8955 - precision: 0.8907 - recall: 0.9018\n",
            "Epoch 10/10\n",
            "35/35 [==============================] - 20s 582ms/step - loss: 0.2843 - accuracy: 0.9107 - precision: 0.9078 - recall: 0.9143\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f02bdb94b50>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "#fitting our model\n",
        "model.fit(x_train, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "TVW09nNTbZzs",
        "outputId": "343ca1f3-00d5-499a-a874-4d92a0199ff3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 8s 598ms/step - loss: 0.2628 - accuracy: 0.9278 - precision: 0.9348 - recall: 0.9198\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.262780100107193, 0.9278075098991394, 0.9347826242446899, 0.9197860956192017]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "#evaluate our model\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluating model using the testing dataset<br>\n",
        "\n",
        "To evaluate the model, we will use the model to classify the data samples in the testing dataset. They should be classified into either ham or spam.\n",
        "\n",
        "The model.predict method will give the prediction results which are in a 2D array, but we want our results in a 1D array. To convert the result from the 2D to 1D array we use the y_predicted.flatten() function.\n",
        "\n"
      ],
      "metadata": {
        "id": "n1Je0os12Jlh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIExcaN9bZzt"
      },
      "outputs": [],
      "source": [
        "#predict our model\n",
        "y_predicted = model.predict(x_test)\n",
        "#y_predicted.flatten()\n",
        "y_predicted=y_predicted.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we used a sigmoid activation function, the prediction probabilities will lie between 0.0 to 1.0. So, if the prediction result is > 0.5 the output should be 1, and if it is < 0.5, the output should be 0."
      ],
      "metadata": {
        "id": "vGqDhbvOGES1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "YiJzWsEbbZzu",
        "outputId": "1a564c7e-7468-4a55-be4b-57c2b5fe58fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "       1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "       1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "#importing numpy\n",
        "import numpy as np\n",
        "y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
        "y_predicted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKK5LwVIbZzv",
        "outputId": "fc7e48a1-e46b-43c8-c38f-54b3ad32f33a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[175,  12],\n",
              "       [ 15, 172]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "#importing the confusion_matrix, classification_report from sklearn\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "#print confusion matrix\n",
        "cm = confusion_matrix(y_test, y_predicted)\n",
        "cm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsdjcE4pbZzw",
        "outputId": "bcfef8c7-a88d-4166-e68c-c98103d70dca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       187\n",
            "           1       0.93      0.92      0.93       187\n",
            "\n",
            "    accuracy                           0.93       374\n",
            "   macro avg       0.93      0.93      0.93       374\n",
            "weighted avg       0.93      0.93      0.93       374\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#print the classification_report\n",
        "print(classification_report(y_test, y_predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlyLFvRMbZzw"
      },
      "source": [
        "#try your inputs\n",
        "\n",
        "You can change your inputs as per you choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AU8YXWUObZzx",
        "outputId": "1d0996d6-8a90-4445-d91a-e1eb3dded581",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7037231 ],\n",
              "       [0.7894425 ],\n",
              "       [0.73930746],\n",
              "       [0.15696658],\n",
              "       [0.07243871]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "reviews = [\n",
        "    'Enter a chance to win $5000, hurry up, offer valid until march 31, 2021',\n",
        "    'You are awarded a SiPix Digital Camera! call 09061221061 from landline. Delivery within 28days. T Cs Box177. M221BP. 2yr warranty. 150ppm. 16 . p pÂ£3.99',\n",
        "    'it to 80488. Your 500 free text messages are valid until 31 December 2005.',\n",
        "    'Hey Sam, Are you coming for a cricket game tomorrow',\n",
        "    \"Why don't you wait 'til at least wednesday to see   if you get your .\"\n",
        "]\n",
        "#predict the model\n",
        "model.predict(reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the output above, the first three email messages have been classified as spam. They have a prediction probability that is greater than 0.5. The last two email messages have been classified as ham. They have a prediction probability that is less than 0.5. These are the right predictions and show we have successfully built our text classification model."
      ],
      "metadata": {
        "id": "T3kVzNfI2fLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, we learned how to build a spam detection model. The model was able to classify email messages as spam or ham. We started by using BERT to convert a given sentence into an embedding vector. This was done using the pre-trained BERT models.\n",
        "\n",
        "We created our model using TensorFlow and initialized all the input and output layers. We followed all the stages of building the neural network and finally came up with a spam detection model. Finally, we used the model to make predictions, the model was able to give accurate predictions."
      ],
      "metadata": {
        "id": "nrTwPJK63Wdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great job!! You have come to the end of this assignment. Treat yourself for this :))\n",
        "\n",
        "![](https://c.tenor.com/pS_wARVlR8kAAAAC/well-done-despicable-me.gif)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "# Do fill this [feedback form](https://forms.zohopublic.in/cloudyml/form/CloudyMLDeepLearningFeedbackForm/formperma/VCFbldnXAnbcgAIl0lWv2blgHdSldheO4RfktMdgK7s)\n",
        "<br>\n",
        "You may head on to the next project section."
      ],
      "metadata": {
        "id": "_RrTTeE94-OF"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}